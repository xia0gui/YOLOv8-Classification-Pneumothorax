# -*- coding: utf-8 -*-
"""EDA-DataPreprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c11hCqcCSk569gzS9H5RdgWICF5sjt_r

**Import Library**
"""

# -*- coding: utf-8 -*-
# Google Colab Setup and Library Imports
from google.colab import drive
import os
import glob
import numpy as np
from PIL import Image
import cv2
import keras
import matplotlib.pyplot as plt
import pandas as pd

# Mount Google Drive
drive.mount('/content/drive')

"""# **EDA**

## **Distribution of Empty vs Non-empty Masks**
"""

import os
import glob
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# Define paths to the files in Google Drive
mask_train_path = '/content/drive/MyDrive/kaggle_dataset/keras_mask_train/masks'
mask_val_path = '/content/drive/MyDrive/kaggle_dataset/keras_mask_val/masks'

# Load all training and validation masks
all_train_masks = glob.glob(os.path.join(mask_train_path, '*'))
all_val_masks = glob.glob(os.path.join(mask_val_path, '*'))

# Function to check if a mask is empty
def is_mask_empty(mask_path):
    mask = np.array(Image.open(mask_path))
    return np.all(mask == 0)

# Count empty and non-empty masks in training
empty_train_masks = [mask for mask in all_train_masks if is_mask_empty(mask)]
non_empty_train_masks = [mask for mask in all_train_masks if not is_mask_empty(mask)]

# Count empty and non-empty masks in validation
empty_val_masks = [mask for mask in all_val_masks if is_mask_empty(mask)]
non_empty_val_masks = [mask for mask in all_val_masks if not is_mask_empty(mask)]

# Output the analysis results
print(f"Total training masks: {len(all_train_masks)}")
print(f"Empty masks in training: {len(empty_train_masks)}")
print(f"Non-empty masks in training: {len(non_empty_train_masks)}")

print(f"Total validation masks: {len(all_val_masks)}")
print(f"Empty masks in validation: {len(empty_val_masks)}")
print(f"Non-empty masks in validation: {len(non_empty_val_masks)}")

# Visualizing the data
labels = ['Non-Empty Train Masks', 'Empty Train Masks', 'Non-Empty Val Masks', 'Empty Val Masks']
counts = [
    len(non_empty_train_masks),
    len(empty_train_masks),
    len(non_empty_val_masks),
    len(empty_val_masks)
]

plt.figure(figsize=(10, 6))
plt.bar(labels, counts, color=['green', 'purple', 'blue', 'pink'])
plt.ylabel('Count')
plt.title('Distribution of Empty and Non-Empty Masks in Training and Validation Sets')
plt.show()

"""# **Data Preprocessing**

## **Classifying Masks into 0 (no pneumothorax) and 1 (pneumothorax) and saving them in new folders**
"""

import os
import glob
import numpy as np
from PIL import Image
import shutil

# Define paths to the files in Google Drive
mask_train_path = '/content/drive/MyDrive/kaggle_dataset/keras_mask_train/masks'
mask_val_path = '/content/drive/MyDrive/kaggle_dataset/keras_mask_val/masks'
im_train_path = '/content/drive/MyDrive/kaggle_dataset/keras_im_train/train'
im_val_path = '/content/drive/MyDrive/kaggle_dataset/keras_im_val/train'

# Define output directories for class 0 and class 1 images
output_class_0_dir = '/content/drive/MyDrive/kaggle_dataset/class_0'
output_class_1_dir = '/content/drive/MyDrive/kaggle_dataset/class_1'

# Create directories if they don't exist
os.makedirs(output_class_0_dir, exist_ok=True)
os.makedirs(output_class_1_dir, exist_ok=True)

# Function to check if a mask is empty
def is_mask_empty(mask_path):
    mask = np.array(Image.open(mask_path))
    return np.all(mask == 0)

# Function to copy images to respective class folders
def copy_images_by_class(mask_paths, image_dir, output_dir_0, output_dir_1):
    for mask_path in mask_paths:
        mask_name = os.path.basename(mask_path)
        # Determine the corresponding image path
        image_path = os.path.join(image_dir, mask_name)
        if not os.path.exists(image_path):
            continue  # Skip if corresponding image is not found

        # Check if the mask is empty
        if is_mask_empty(mask_path):
            shutil.copy(image_path, os.path.join(output_dir_0, mask_name))
        else:
            shutil.copy(image_path, os.path.join(output_dir_1, mask_name))

# Copy training images
copy_images_by_class(
    glob.glob(os.path.join(mask_train_path, '*')),
    im_train_path,
    output_class_0_dir,
    output_class_1_dir
)

# Copy validation images
copy_images_by_class(
    glob.glob(os.path.join(mask_val_path, '*')),
    im_val_path,
    output_class_0_dir,
    output_class_1_dir
)

print(f"Images have been successfully separated into '{output_class_0_dir}' and '{output_class_1_dir}'")

"""Checking total number of images in class 0 and 1"""

import os

# Define the directories
output_class_0_dir = '/content/drive/MyDrive/kaggle_dataset/class_0'
output_class_1_dir = '/content/drive/MyDrive/kaggle_dataset/class_1'

# Function to count images in a directory
def count_images(directory):
    # List all files in the directory
    files = os.listdir(directory)
    # Filter for image files (e.g., .jpg, .png, .jpeg)
    image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]
    return len(image_files)

# Count images in each directory
class_0_count = count_images(output_class_0_dir)
class_1_count = count_images(output_class_1_dir)

# Print the results
print(f"Number of images in class_0 directory: {class_0_count}")
print(f"Number of images in class_1 directory: {class_1_count}")

"""## **K-meas Clustering (old)**

**Normalise pixel value, flatten image to 1D array**
"""

import cv2
import os
import numpy as np

# Define image folder path
image_folder = '/content/drive/MyDrive/kaggle_dataset/class_0'
image_data = []

# Load and preprocess images
for image_name in os.listdir(image_folder):
    image_path = os.path.join(image_folder, image_name)
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale
    if image is not None:  # Ensure the image was loaded correctly
        image_data.append(image)

# Convert list to NumPy array
image_data = np.array(image_data, dtype=np.float32)

# Normalize pixel values to the range [0, 1]
image_data /= 255.0

print(f"Shape of image data: {image_data.shape}")

# Flatten images
num_images, height, width = image_data.shape
flattened_images = image_data.reshape(num_images, height * width)  # (num_images, height*width)
print("Shape of flattened images:", flattened_images.shape)  # (num_images, height*width)

"""**Reducing features to 100**"""

from sklearn.decomposition import PCA

pca = PCA(n_components=100, random_state=42)  # Reduce to 100 features
reduced_images = pca.fit_transform(flattened_images)
print("Shape after PCA:", reduced_images.shape)  # (9378, 100)

"""**k-means clustering - ELbow Method**"""

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Determine the optimal number of clusters
inertia = []
for k in range(1, 11):  # Test for k=1 to k=10
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(flattened_images)
    inertia.append(kmeans.inertia_)

# Plot the Elbow Curve
plt.plot(range(1, 11), inertia, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.show()

"""**Silhouette Score**"""

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

silhouette_scores = []

# Test for different values of k
for k in range(2, 11):  # Start from k=2 (k=1 isn't meaningful for clustering)
    kmeans = KMeans(n_clusters=k, random_state=42)
    cluster_labels = kmeans.fit_predict(flattened_images)
    silhouette_avg = silhouette_score(flattened_images, cluster_labels)
    silhouette_scores.append(silhouette_avg)
    print(f"Silhouette Score for k={k}: {silhouette_avg}")

import matplotlib.pyplot as plt

plt.plot(range(2, 11), silhouette_scores, marker='o')
plt.title('Silhouette Scores for Different k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Silhouette Score')
plt.show()

"""**Euclidean Distance 2D Graph**"""

import cv2
import os
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Step 1: Load and preprocess X-ray images
image_folder = '/content/drive/MyDrive/kaggle_dataset/class_0'  # Update the path if needed
image_data = []

# Load and preprocess images
for image_name in os.listdir(image_folder):
    image_path = os.path.join(image_folder, image_name)
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale
    if image is not None:  # Ensure the image was loaded correctly
        image_data.append(image)

# Convert list to NumPy array
image_data = np.array(image_data, dtype=np.float32)

# Normalize pixel values to the range [0, 1]
image_data /= 255.0

# Flatten images
num_images, height, width = image_data.shape
flattened_images = image_data.reshape(num_images, height * width)  # (num_images, height*width)

print("Shape of flattened images:", flattened_images.shape)

# Step 2: Apply KMeans clustering with 5 clusters
kmeans = KMeans(n_clusters=5, random_state=42)
labels = kmeans.fit_predict(flattened_images)
centroids = kmeans.cluster_centers_

# Step 3: Reduce dimensions for visualization using PCA
pca = PCA(n_components=2)
flattened_images_2d = pca.fit_transform(flattened_images)  # Reduce data to 2D
centroids_2d = pca.transform(centroids)  # Transform centroids to 2D

# Step 4: Plot the clusters
plt.figure(figsize=(10, 6))
colors = ['orange', 'pink', 'yellow', 'blue', 'green']

for i in range(5):  # 5 clusters
    cluster_data = flattened_images_2d[labels == i]
    plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=f'Cluster {i+1}', alpha=0.7, s=30, color=colors[i])

# Plot centroids
plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1], c='red', marker='X', s=200, label='Centroids')

# Example Euclidean distance (from a point to its centroid)
example_point = flattened_images_2d[0]  # Pick a point from the dataset
assigned_centroid = centroids_2d[labels[0]]  # Get its corresponding centroid
plt.plot([example_point[0], assigned_centroid[0]], [example_point[1], assigned_centroid[1]],
         'k--', label='Euclidean Distance Example')

# Plot formatting
plt.title('K-means Clustering with Euclidean Distance (5 Clusters)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend()
plt.grid()
plt.show()

"""**Euclidean Distance 3D Graph**"""

import cv2
import os
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Step 1: Load and preprocess X-ray images
image_folder = '/content/drive/MyDrive/kaggle_dataset/class_0'  # Update the path if needed
image_data = []

# Load and preprocess images
for image_name in os.listdir(image_folder):
    image_path = os.path.join(image_folder, image_name)
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale
    if image is not None:  # Ensure the image was loaded correctly
        image_data.append(image)

# Convert list to NumPy array
image_data = np.array(image_data, dtype=np.float32)

# Normalize pixel values to the range [0, 1]
image_data /= 255.0

# Flatten images
num_images, height, width = image_data.shape
flattened_images = image_data.reshape(num_images, height * width)  # (num_images, height*width)

print("Shape of flattened images:", flattened_images.shape)

# Step 2: Apply KMeans clustering with 5 clusters
kmeans = KMeans(n_clusters=5, random_state=42)
labels = kmeans.fit_predict(flattened_images)
centroids = kmeans.cluster_centers_

# Step 3: Reduce dimensions for visualization using PCA
pca = PCA(n_components=3)
flattened_images_3d = pca.fit_transform(flattened_images)  # Reduce data to 3D
centroids_3d = pca.transform(centroids)  # Transform centroids to 3D

# Step 4: Plot the clusters in 3D
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
colors = ['orange', 'pink', 'yellow', 'blue', 'green']

for i in range(5):  # 5 clusters
    cluster_data = flattened_images_3d[labels == i]
    ax.scatter(cluster_data[:, 0], cluster_data[:, 1], cluster_data[:, 2], label=f'Cluster {i+1}', alpha=0.7, s=30, color=colors[i])

# Plot centroids
ax.scatter(centroids_3d[:, 0], centroids_3d[:, 1], centroids_3d[:, 2], c='red', marker='X', s=200, label='Centroids')

# Example Euclidean distance (optional for illustration)
example_point = flattened_images_3d[0]  # Pick a point from the dataset
assigned_centroid = centroids_3d[labels[0]]  # Get its corresponding centroid
ax.plot([example_point[0], assigned_centroid[0]],
        [example_point[1], assigned_centroid[1]],
        [example_point[2], assigned_centroid[2]],
        'k--', label='Euclidean Distance Example')

# Plot formatting
ax.set_title('K-means Clustering with Euclidean Distance (3D Visualization)')
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_zlabel('Principal Component 3')
ax.legend()
plt.show()

"""**cluster images**"""

import random
import matplotlib.pyplot as plt

# Apply K-Means with optimal k
optimal_k = 5  # Replace with your chosen k
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
cluster_labels = kmeans.fit_predict(flattened_images)

print("Cluster labels:", cluster_labels)  # Each image is assigned a cluster label

# Visualize some images from each cluster
for cluster_id in range(optimal_k):
    cluster_indices = np.where(cluster_labels == cluster_id)[0]  # Indices of images in this cluster
    cluster_sample_indices = random.sample(list(cluster_indices), 5)  # Select 5 random images
    plt.figure(figsize=(10, 5))
    for i, idx in enumerate(cluster_sample_indices):
        plt.subplot(1, 5, i + 1)
        plt.imshow(image_data[idx], cmap='gray')
        plt.title(f"Cluster {cluster_id}")
        plt.axis('off')
    plt.show()

"""## **ResNet 50**"""

import os
from PIL import Image
import torch
from torchvision import transforms
from tqdm import tqdm


# Define the directory containing your images
output_class_0_dir = '/content/drive/MyDrive/kaggle_dataset/class_0'

# Define the output directory for processed images
processed_output_dir = '/content/drive/MyDrive/kaggle_dataset/processed_class_0'
os.makedirs(processed_output_dir, exist_ok=True)  # Create directory if it doesn't exist

# Define the preprocessing pipeline
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize to 224x224 (input size for ResNet)
    transforms.ToTensor(),          # Convert to PyTorch tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize
])

# Function to load, preprocess, and save images
def load_preprocess_and_save_images(image_dir, preprocess, output_dir):
    file_list = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]
    for filename in tqdm(file_list, desc="Processing Images", unit="image"):
        img_path = os.path.join(image_dir, filename)
        image = Image.open(img_path).convert('RGB')  # Convert to RGB if grayscale

        # Apply preprocessing (excluding tensor normalization for saving)
        resized_image = preprocess.transforms[0](image)  # Resize
        tensor_image = preprocess.transforms[1](resized_image)  # Convert to Tensor

        # Convert back to PIL Image for saving (scale tensor values to 0-255)
        processed_image = transforms.ToPILImage()(tensor_image)

        # Save the processed image
        output_path = os.path.join(output_dir, filename)
        processed_image.save(output_path)

# Preprocess and save images with a progress bar
load_preprocess_and_save_images(output_class_0_dir, preprocess, processed_output_dir)

print(f"Processed images saved to: {processed_output_dir}")

"""**Load a pre-trained ResNet model: ResNet-50**"""

import os
from PIL import Image
import torch
from torchvision import transforms
from tqdm import tqdm
import torchvision.models as models
import torch.nn as nn
import numpy as np

# Define directories
processed_output_dir = '/content/drive/MyDrive/kaggle_dataset/processed_class_0'
feature_output_dir = '/content/drive/MyDrive/kaggle_dataset/features_class_0'
os.makedirs(feature_output_dir, exist_ok=True)  # Create directory to store features

# Define the preprocessing pipeline for loading preprocessed images
preprocess_for_tensor = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load the ResNet model for feature extraction
resnet = models.resnet50(pretrained=True)
feature_extractor = nn.Sequential(*list(resnet.children())[:-1])  # Remove FC layer
feature_extractor.eval()

# Define a function to extract features from preprocessed images
def extract_features(image_dir, model, preprocess, output_dir):
    features_list = []
    filenames = []

    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]
    print(f"Number of valid image files: {len(image_files)}")

    for filename in tqdm(image_files, desc="Extracting Features", unit="image"):
        print(f"Processing file: {filename}")  # Debugging print statement
        img_path = os.path.join(image_dir, filename)

        # Load and preprocess image
        image = Image.open(img_path).convert('RGB')
        tensor_image = preprocess(image).unsqueeze(0)  # Add batch dimension

        # Pass through the feature extractor
        with torch.no_grad():
            features = model(tensor_image).squeeze()  # Remove batch dimension
        features_list.append(features.numpy())
        filenames.append(filename)

        # Save the feature with the same name as the image file (replace extension with .npy)
        feature_path = os.path.join(output_dir, f'{os.path.splitext(filename)[0]}.npy')
        print(f"Saving feature to: {feature_path}")  # Debugging print statement
        with open(feature_path, 'wb') as f:
            np.save(f, features)

    return features_list, filenames

# Extract features and save them
features, filenames = extract_features(processed_output_dir, feature_extractor, preprocess_for_tensor, feature_output_dir)

print(f"Number of features extracted: {len(features)}")
print(f"Extracted features saved to: {feature_output_dir}")
print(f"Number of saved features: {len(os.listdir(feature_output_dir))}")

print(f"Number of features saved: {len(os.listdir(feature_output_dir))}")

"""## **K-means Clustering (new)**

**Load into single array**
"""

import os
import numpy as np

# Load all feature vectors into a single array
feature_dir = '/content/drive/MyDrive/kaggle_dataset/features_class_0'
features = [np.load(os.path.join(feature_dir, f)) for f in os.listdir(feature_dir) if f.endswith('.npy')]
feature_matrix = np.vstack(features)  # Combine all feature vectors into a matrix

print(f"Feature matrix shape: {feature_matrix.shape}")

import os
feature_dir = '/content/drive/MyDrive/kaggle_dataset/features_class_0'
features = [np.load(os.path.join(feature_dir, f)) for f in os.listdir(feature_dir) if f.endswith('.npy')]
print(f"Number of loaded features: {len(features)}")

from sklearn.cluster import KMeans

K = 5  # Number of clusters
kmeans = KMeans(n_clusters=K, random_state=42)
cluster_labels = kmeans.fit_predict(feature_matrix)

import os
import shutil

# Define directories
feature_dir = '/content/drive/MyDrive/kaggle_dataset/features_class_0'  # Directory containing .npy files
output_class_0_dir = '/content/drive/MyDrive/kaggle_dataset/class_0'    # Directory containing .png images
output_image_dir = '/content/drive/MyDrive/kaggle_dataset/clustered_images'  # Directory to save clustered images

# Extract filenames from .npy files
filenames = [f for f in os.listdir(feature_dir) if f.endswith('.npy')]  # Full .npy filenames

# Pair filenames with cluster labels
image_clusters = list(zip(filenames, cluster_labels))  # Pair .npy filenames with cluster labels

# Create directories for each cluster
os.makedirs(output_image_dir, exist_ok=True)
for cluster in set(cluster_labels):
    cluster_dir = os.path.join(output_image_dir, f'cluster_{cluster}')
    os.makedirs(cluster_dir, exist_ok=True)

# Copy .png images to their respective cluster directories
for filename, cluster in image_clusters:
    # Convert .npy filename to corresponding .png filename
    image_name = os.path.splitext(filename)[0] + '.png'
    src_path = os.path.join(output_class_0_dir, image_name)

    # Destination path in the cluster directory
    cluster_dir = os.path.join(output_image_dir, f'cluster_{cluster}')
    dest_path = os.path.join(cluster_dir, image_name)  # Save as .png file

    if os.path.exists(src_path):
        shutil.copy(src_path, dest_path)  # Copy the .png file
        print(f"Copied: {src_path} -> {dest_path}")
    else:
        print(f"Image not found: {src_path}")

"""**Euclidean Distance graph**"""

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Reduce feature dimensions to 2 for visualization
pca = PCA(n_components=2)
reduced_features = pca.fit_transform(feature_matrix)

# Plot clusters
plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=cluster_labels, cmap='viridis')
plt.colorbar(label='Cluster')
plt.title('K-Means Clusters of Class 0 Features')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.show()

"""**Save results**"""

import pandas as pd

cluster_results = pd.DataFrame({'Image': filenames, 'Cluster': cluster_labels})
cluster_results.to_csv('/content/drive/MyDrive/kaggle_dataset/cluster_results.csv', index=False)
print("Cluster assignments saved to cluster_results.csv")

"""**Group images by cluster**"""

import os
import shutil
from PIL import Image
import matplotlib.pyplot as plt

# Assuming `filenames` and `cluster_labels` are already defined
# Map filenames to their respective clusters
clusters = {}
for filename, label in zip(filenames, cluster_labels):
    if label not in clusters:
        clusters[label] = []
    clusters[label].append(filename)

# Print the number of images in each cluster
for cluster_id, images in clusters.items():
    print(f"Cluster {cluster_id}: {len(images)} images")

import os
import random
from PIL import Image
import matplotlib.pyplot as plt

def display_random_images_from_class(class_label, folder_path, n=5):
    """
    Display `n` random images from the given folder with a specific class label.
    """
    # Collect all image paths in the folder
    image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.png')]

    if len(image_files) == 0:
        print(f"No images found in {folder_path}")
        return

    # Ensure there are enough images to display
    if len(image_files) < n:
        print(f"Not enough images in {folder_path}. Displaying {len(image_files)} images instead.")
        n = len(image_files)

    # Randomly select `n` images
    selected_images = random.sample(image_files, n)

    # Display the images
    print(f"class {class_label}:")
    plt.figure(figsize=(15, 10))
    for i, img_path in enumerate(selected_images):
        image = Image.open(img_path)  # Open the image
        plt.subplot(1, n, i + 1)
        plt.imshow(image)  # Display in original color (no colormap applied)
        plt.axis('off')
        plt.title(os.path.basename(img_path))
    plt.show()

# Paths to the cluster folders
cluster_paths = {
    0: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_0',
    1: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_1',
    2: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_2',
    3: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_3',
    4: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_4',
}

# Display random images from each cluster
for class_label, folder_path in cluster_paths.items():
    display_random_images_from_class(class_label, folder_path, n=5)

import os
import shutil
from math import floor

# Directory to save selected images
selected_images_dir = '/content/drive/MyDrive/kaggle_dataset/selected_class_0'
os.makedirs(selected_images_dir, exist_ok=True)

# Clustered image directories
cluster_dirs = {
    0: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_0',
    1: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_1',
    2: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_2',
    3: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_3',
    4: '/content/drive/MyDrive/kaggle_dataset/clustered_images/cluster_4',
}

# Fractions of images to select from each cluster
total_images = 2669
cluster_fractions = {
    0: (4 / 17) * total_images,
    1: (5 / 17) * total_images,
    2: (3 / 17) * total_images,
    3: (2 / 17) * total_images,
    4: (3 / 17) * total_images,
}

# Select images from each cluster
for cluster_id, cluster_path in cluster_dirs.items():
    num_images_to_select = floor(cluster_fractions[cluster_id])  # Calculate the number of images to select
    print(f"Selecting {num_images_to_select} images from Cluster {cluster_id}")

    # Get all images in the cluster directory
    image_list = [f for f in os.listdir(cluster_path) if f.endswith('.png')]

    # Ensure we don't exceed the available number of images
    if num_images_to_select > len(image_list):
        print(f"Not enough images in Cluster {cluster_id}. Only {len(image_list)} images available.")
        num_images_to_select = len(image_list)

    # Select the first `num_images_to_select` images
    selected_images = image_list[:num_images_to_select]

    # Copy the selected images to the output directory
    for image_name in selected_images:
        src_path = os.path.join(cluster_path, image_name)
        dest_path = os.path.join(selected_images_dir, image_name)  # Keep the original file name
        shutil.copy(src_path, dest_path)

print(f"Selected images saved to {selected_images_dir}")

import os

# Define the directory
selected_images_dir = '/content/drive/MyDrive/kaggle_dataset/selected_class_0'

# Count the number of image files
image_count = len([f for f in os.listdir(selected_images_dir) if f.endswith('.png')])

# Print the result
print(f"Total number of images in '{selected_images_dir}': {image_count}")